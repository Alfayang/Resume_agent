# examples/research/server.py
import os
import sys
import json
import uuid
import time
import random
import logging
import uvicorn
from typing import Any, List, Dict, Optional

from fastapi import FastAPI, Header, HTTPException, Query, BackgroundTasks
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware

# è®© python æ‰¾åˆ° src/deepagents
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../src")))

# åˆ›å»º Agent çš„å·¥å‚
try:
    from deepagents import create_deep_agent
except Exception:
    from deepagents.agent_factory import create_deep_agent

# ä½ çš„å·¥å…·ï¼ˆæŒ‰ä½ çš„å®é™…è·¯å¾„ï¼‰
from deepagents.tools.text_parse_tool import parse_resume_text_tool
from deepagents.tools.rewrite_tool import rewrite_text_tool
from deepagents.tools.expand_tool import expand_text_tool
from deepagents.tools.compress_tool import contract_text_tool
from deepagents.tools.evaluate_resume_tool import evaluate_resume_tool
from deepagents.tools.generate_statement_tool import generate_statement_tool
from deepagents.tools.generate_recommend_tool import generate_recommendation_tool
from deepagents.tools.document_name_tool import name_document_tool

# æœ€ç®€å•æ–‡ä»¶è®°å¿†
from deepagents.simple_file_memory import save_memory, load_memory, clear_memory

# LangGraphï¼ˆå¯é€‰ï¼‰
from langgraph.graph import StateGraph, START, END
from deepagents.state import DeepAgentState

# è¿è¡Œæ€/ToDo/æ ¡éªŒ/æŒä¹…åŒ–
from deepagents.run_state import (
    configure_runtime,
    append_step,
    set_validation,
    load_state as load_trace_state,
    list_states as list_trace_states,
    get_runtime_dirs,
    create_run_state,
    update_memory_state,
)

# ä¸‰è§’è‰²è°ƒåº¦ï¼ˆæ³¨æ„ï¼šæ­¤å¤„æŒ‰ä½ çš„å¯¼å…¥è·¯å¾„ï¼‰
from deepagents.tri_role_scheduler import run_textual_flow

# ====== å­ä»£ç† ======
doc_writer_subagent = {
    "name": "doc-writer",
    "description": "æ–‡ä¹¦/ç®€å†ä»»åŠ¡ä¸“å®¶ï¼šè§£æã€é‡å†™ã€æ‰©å†™ã€ç²¾ç®€ã€è¯„ä¼°ã€ç”Ÿæˆä¸ªäººé™ˆè¿°/æ¨èä¿¡ã€æ–‡æ¡£å‘½åã€‚",
    "prompt": (
        "ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ–‡ä¹¦ä¸ç®€å†åŠ©æ‰‹ã€‚\n"
        "ä½ å°†æ”¶åˆ°ä¸€ä¸ª JSON æŒ‡ä»¤ï¼Œå½¢å¦‚ï¼š{\"action\": \"...\", \"inputs\": {...}, \"model\": \"...\"}ã€‚\n\n"
        "ã€é‡è¦çº¦å®šã€‘\n"
        "- è‹¥ inputs.fix_guidance å­˜åœ¨ï¼Œå¿…é¡»ä¸¥æ ¼ä¾æ®å…¶ä¸­çš„ä¿®æ­£ç‚¹å¯¹ç»“æœè¿›è¡Œä¿®æ”¹ä¸ä¼˜åŒ–ã€‚\n"
        "- ç»Ÿä¸€è¦æ±‚ï¼šåªè¾“å‡ºæœ€ç»ˆç»“æœï¼Œä¸è¦åŒ…å«è§£é‡Šã€è¿‡ç¨‹æè¿°æˆ–å¤šä½™æ ‡æ³¨ã€‚\n\n"
        "ã€åŠ¨ä½œä¸å¤„ç†ã€‘\n"
        "- action == \"rewrite_letter\"ï¼šä½¿ç”¨ inputs.referencesï¼ˆå¯é€‰ï¼‰ä¸ inputs.letterï¼ˆåŸæ–‡ï¼‰è¿›è¡Œæ”¹å†™ï¼›åªè¾“å‡ºæ”¹å†™åçš„æœ€ç»ˆæ–‡æœ¬ã€‚\n"
        "- action == \"expand\" / \"contract\"ï¼šå¯¹ inputs.text è¿›è¡Œæ‰©å†™æˆ–å‹ç¼©ï¼›åªè¾“å‡ºä¿®æ”¹åçš„æœ€ç»ˆæ–‡æœ¬ã€‚\n"
        "- action == \"evaluate_resume\"ï¼šåŸºäº inputs.dataï¼ˆç®€å† JSONï¼‰è¿›è¡Œè¯„ä»·ï¼›è¾“å‡ºè¯„ä»·/å»ºè®®æ–‡æœ¬ã€‚\n"
        "- action == \"generate_statement\"ï¼šæ ¹æ® inputs.text ç”Ÿæˆä¸ªäººé™ˆè¿°ï¼›è¾“å‡ºæœ€ç»ˆç»“æœã€‚\n"
        "- action == \"generate_recommendation\"ï¼šæ ¹æ® inputs.text ç”Ÿæˆæ¨èä¿¡ï¼›è¾“å‡ºæœ€ç»ˆç»“æœã€‚\n"
        "- action == \"name_document\"ï¼šæ ¹æ® inputs.textï¼ˆMarkdownï¼‰ç”Ÿæˆç®€æ´æ ‡é¢˜ï¼›åªè¾“å‡ºæ ‡é¢˜å­—ç¬¦ä¸²ã€‚\n"
        "- action == \"parse_resume_text\"ï¼šå°† inputs.textï¼ˆç®€å†çº¯æ–‡æœ¬ï¼‰è§£æä¸ºç»“æ„åŒ– JSONï¼›åªè¾“å‡ºè§£æåçš„ JSONã€‚"
    ),
    "tools": [
        "parse_resume_text",
        "rewrite_text",
        "expand_text",
        "contract_text",
        "evaluate_resume",
        "generate_statement",
        "generate_recommendation",
        "name_document",
    ],
}

# ====== ä¸» Agent Prompt ======
main_prompt = """
ä½ æ˜¯ç¼–æ’ä»£ç†ï¼ˆorchestration agentï¼‰ã€‚
å½“æ¥åˆ°ç”¨æˆ·çš„æ–‡ä¹¦/ç®€å†ç±»è¯·æ±‚æ—¶ï¼Œè¯·ä¼˜å…ˆè°ƒç”¨ `task` å·¥å…·ï¼Œå°†ä»»åŠ¡å§”æ´¾ç»™å­ä»£ç† `doc-writer`ï¼Œ
å¹¶ä»¥å¦‚ä¸‹ JSON ä½œä¸º description ä¼ å…¥ï¼š
{
  "action": "<rewrite_letter | expand | contract | evaluate_resume | generate_statement | generate_recommendation | name_document | parse_resume_text>",
  "inputs": { ... },
  "model": "deepseek_v3"
}
æœ€ç»ˆå“åº”åªåŒ…å«æœ€ç»ˆç»“æœï¼Œä¸è¦é™„åŠ è§£é‡Šä¸è¿‡ç¨‹ã€‚
"""

# ====== åˆ›å»ºä¸» Agentï¼šåªæš´éœ² task ======
agent = create_deep_agent(
    tools=[
        parse_resume_text_tool,
        rewrite_text_tool,
        expand_text_tool,
        contract_text_tool,
        evaluate_resume_tool,
        generate_statement_tool,
        generate_recommendation_tool,
        name_document_tool,
    ],
    instructions=main_prompt,
    subagents=[doc_writer_subagent],
    expose_tools_to_main=False,  # ä¸» Agent åªçœ‹åˆ° taskï¼Œä¸šåŠ¡å·¥å…·èµ°å­ä»£ç†
)

# ====== LangGraphï¼ˆå¯é€‰ï¼‰======
def _pick_output(result: Any) -> str:
    """ä» agent è¿”å›ç»“æ„é‡Œå°½é‡å–åˆ°æœ€ç»ˆæ–‡æœ¬"""
    if isinstance(result, dict):
        for k in [
            "rewritten_text",
            "contracted_text",
            "expanded_text",
            "document_name",
            "generated_statement",
            "generated_recommendation",
        ]:
            v = result.get(k)
            if v:
                return v
        msgs = result.get("messages") or []
        for m in reversed(msgs):
            if hasattr(m, "content"):
                content = m.content
                addkw = getattr(m, "additional_kwargs", {}) or {}
            else:
                content = m.get("content")
                addkw = m.get("additional_kwargs", {}) or {}
            if not content:
                continue
            if isinstance(addkw, dict) and "tool_calls" in addkw:
                continue
            return content
    return str(result)

def build_langgraph_app(underlying_agent):
    """æ„å»ºä¸€ä¸ªå¾ˆè–„çš„ planâ†’delegate å›¾ï¼›delegate å†…éƒ¨ä»è°ƒç”¨ underlying_agent"""
    graph = StateGraph(DeepAgentState)

    def plan_node(state: DeepAgentState):
        # ä¸å†å†™æ­» ToDoï¼›LangGraph åœ¨æ­¤åªæ˜¯æ¼”ç¤ºç”¨é€”
        return {}

    def delegate_node(state: DeepAgentState):
        msgs = state.get("messages", [])
        res = underlying_agent.invoke({"messages": msgs})
        text = _pick_output(res)
        return {
            "rewritten_text": text,
            "rewritten_texts": [text],
        }

    graph.add_node("plan", plan_node)
    graph.add_node("delegate", delegate_node)
    graph.add_edge(START, "plan")
    graph.add_edge("plan", "delegate")
    graph.add_edge("delegate", END)

    return graph.compile()

LG_ENABLED = os.getenv("USE_LANGGRAPH", "0") == "1"
lg_app = build_langgraph_app(agent) if LG_ENABLED else None

# ====== FastAPI & Logger ======
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | pid=%(process)d | %(levelname)s | %(message)s",
)

# ====== Models ======
class Question(BaseModel):
    user_input: str
    session_id: Optional[str] = None

# ====== Config ======
RETRY_ATTEMPTS = int(os.getenv("AGENT_RETRY_ATTEMPTS", "5"))
RETRY_BASE = float(os.getenv("AGENT_RETRY_BASE", "2.0"))
RETRY_JITTER = float(os.getenv("AGENT_RETRY_JITTER", "1.0"))

# é…ç½®è¿è¡Œç›®å½•ï¼ˆrun_state ä¼šç¡®ä¿ç›®å½•å­˜åœ¨ï¼‰
from deepagents.run_state import configure_runtime as _cfg_runtime
_cfg_runtime(
    run_dir=os.getenv("RUN_DIR", "./run_store"),
    mem_dir=os.getenv("MEMORY_DIR", "./mem_store"),
)

# ====== Helpers ======
def _sleep_backoff(i: int):
    delay = RETRY_BASE * (2**i) + random.uniform(0, RETRY_JITTER)
    time.sleep(delay)

def invoke_agent_with_retry(messages: List[Dict[str, str]]) -> Dict[str, Any]:
    """ç»Ÿä¸€çš„è°ƒç”¨å…¥å£ï¼šä¼˜å…ˆèµ° LangGraphï¼›å¤±è´¥é‡è¯•ï¼›æœ€ç»ˆå…œåº•å›æ˜¾ç”¨æˆ·è¾“å…¥"""
    last_err = None
    for i in range(RETRY_ATTEMPTS):
        try:
            if LG_ENABLED and lg_app is not None:
                # LangGraph è·¯å¾„
                state = lg_app.invoke({"messages": messages})
                txt = state.get("rewritten_text")
                if not txt:
                    # å…œåº•å†è°ƒä¸€æ¬¡åº•å±‚ agent
                    res = agent.invoke({"messages": messages})
                    txt = _pick_output(res)
                return {"rewritten_text": txt}
            else:
                # ç›´è¿è·¯å¾„
                return agent.invoke({"messages": messages})
        except Exception as e:
            last_err = e
            _sleep_backoff(i)

    # å…¨å¤±è´¥ï¼šå›é€€ä¸ºæœ€åä¸€æ¡ç”¨æˆ·è¾“å…¥
    last_user = next(
        (m["content"] for m in reversed(messages) if m.get("role") == "user"), ""
    )
    return {"rewritten_text": last_user}

# ====== è·¯ç”±ï¼ˆä½¿ç”¨ä¸‰è§’è‰²è½®è½¬ï¼‰======
@app.post("/generate")
async def generate_report(
    q: Question, 
    background_tasks: BackgroundTasks,  # 1. æ³¨å…¥ BackgroundTasks ä¾èµ–
    x_session_id: Optional[str] = Header(default=None)
):
    try:
        # 1) Entranceï¼šä¼šè¯ & å†å²
        session_id = x_session_id or q.session_id or str(uuid.uuid4())
        last_n = int(os.getenv("MEMORY_LOAD_LAST_N", "8"))
        history = load_memory(session_id, last_n=last_n)

        # 2) ç«‹å³åˆ›å»ºè¿è¡ŒçŠ¶æ€å¹¶è¿”å›trace_id
        run_state = create_run_state(session_id, q.user_input)
        trace_id = run_state["trace_id"]
        
        # 3) åœ¨åå°å¼‚æ­¥å¤„ç†ä»»åŠ¡ (è¿™æ˜¯ä¸»è¦ä¿®æ”¹)
        # ä¸å†éœ€è¦è‡ªå·±å®šä¹‰ process_taskï¼Œç›´æ¥å°†è¦æ‰§è¡Œçš„å‡½æ•°å’Œå‚æ•°æ·»åŠ åˆ°åå°ä»»åŠ¡
        background_tasks.add_task(
            run_textual_flow_wrapper,  # ä½¿ç”¨ä¸€ä¸ªæ–°çš„åŒ…è£…å‡½æ•°
            trace_id=trace_id,
            session_id=session_id,
            user_input=q.user_input,
            history=history
        )
        
        # 4) ç«‹å³è¿”å›trace_idï¼Œè®©å‰ç«¯å¼€å§‹ç›‘å¬çŠ¶æ€
        # è¿™ä¸ªå“åº”ä¼šç«‹åˆ»å‘é€ï¼Œä¸ä¼šç­‰å¾… run_textual_flow_wrapper æ‰§è¡Œå®Œæ¯•
        from fastapi.responses import JSONResponse
        return JSONResponse({
            "trace_id": trace_id,
            "session_id": session_id,
            "status": "started",
            "message": "ä»»åŠ¡å·²å¼€å§‹ï¼Œæ­£åœ¨å¤„ç†ä¸­..."
        })
    except Exception as e:
        print(f"âŒ Generateç«¯ç‚¹é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

# 5. åˆ›å»ºä¸€ä¸ªæ–°çš„åŒ…è£…å‡½æ•°æ¥åŒ…å«åŸæ¥çš„é€»è¾‘
def run_textual_flow_wrapper(trace_id: str, session_id: str, user_input: str, history: list):
    """
    è¿™ä¸ªå‡½æ•°åŒ…å«äº†æ‰€æœ‰éœ€è¦åœ¨åå°è¿è¡Œçš„é˜»å¡é€»è¾‘ã€‚
    """
    try:
        # æ›´æ–°å†…å­˜çŠ¶æ€ä¸ºå¼€å§‹å¤„ç†
        from deepagents.run_state import update_memory_state
        update_memory_state(trace_id, {
            "plan_rationale": "æ­£åœ¨åˆ†ææ‚¨çš„è¯·æ±‚...",
            "todo": [{"step": "prepare", "status": "in_progress", "desc": "æ­£åœ¨å‡†å¤‡ä»»åŠ¡ç¯å¢ƒ"}]
        })
        
        # è·‘ Textual Flow
        result = run_textual_flow(
            user_input=user_input,
            session_id=session_id,
            history=history,
            pick_output=_pick_output,
            agent_invoke_with_retry=invoke_agent_with_retry,
            plan_max_loops=int(os.getenv("PLAN_MAX_LOOPS","3")),
            step_max_attempts=int(os.getenv("STEP_MAX_ATTEMPTS","2")),
            pass_threshold=float(os.getenv("VAL_PASS_THRESHOLD","0.75")),
            overall_replan_max=int(os.getenv("OVERALL_REPLAN_MAX","1")),
        )

        output = result.get("final_text","")

        # Memoryï¼šè®°å½•å¯¹è¯
        try:
            save_memory(session_id, "user", user_input)
            save_memory(session_id, "assistant", output)
            append_step(result["trace_id"], "persist_memory", "ok")
        except Exception as e:
            append_step(result["trace_id"], "persist_memory", "error", {"error": str(e)})

        # æ›´æ–°æœ€ç»ˆç»“æœåˆ°å†…å­˜çŠ¶æ€
        update_memory_state(trace_id, {
            "final_text": output,
            "done": result["done"],
            "plan_rationale": result.get("plan_rationale",""),
            "validation": {"ok": result["done"], "status": "completed" if result["done"] else "failed"}
        })
        
    except Exception as e:
        print(f"âŒ ä»»åŠ¡å¤„ç†å¤±è´¥: {e}")
        # æ›´æ–°é”™è¯¯çŠ¶æ€
        from deepagents.run_state import update_memory_state
        update_memory_state(trace_id, {
            "error": str(e),
            "validation": {"ok": False, "status": "failed", "feedback": [str(e)]}
        })

@app.post("/debug")
async def debug_report(
    q: Question, x_session_id: Optional[str] = Header(default=None)
):
    """ç›´æ¥è°ƒåº•å±‚ agentï¼Œè¿”å› messages è§†å›¾ï¼ˆä¾¿äºæ’æŸ¥ tool_callsï¼‰"""
    session_id = x_session_id or q.session_id or str(uuid.uuid4())
    history = load_memory(session_id, last_n=int(os.getenv("MEMORY_LOAD_LAST_N", "8")))
    messages: List[Dict[str, str]] = []
    for h in history:
        messages.append(
            {"role": h.get("role") or "user", "content": h.get("content") or ""}
        )
    messages.append({"role": "user", "content": q.user_input})

    res = agent.invoke({"messages": messages})
    msgs = res.get("messages", [])

    def view(m):
        return {
            "type": m.__class__.__name__ if hasattr(m, "__class__") else str(type(m)),
            "content": getattr(m, "content", None)
            if hasattr(m, "content")
            else m.get("content", None),
            "kwargs": getattr(m, "additional_kwargs", {})
            if hasattr(m, "additional_kwargs")
            else m.get("additional_kwargs", {}),
        }

    return {"session_id": session_id, "messages": [view(m) for m in msgs]}

@app.post("/memory/clear")
async def clear_session_memory(session_id: Optional[str] = Header(default=None)):
    if not session_id:
        raise HTTPException(status_code=400, detail="Missing session_id in header")
    clear_memory(session_id)
    return {"ok": True, "session_id": session_id}

@app.get("/health")
def health_check():
    ok = True
    try:
        dirs = get_runtime_dirs()
        os.makedirs(dirs["run_dir"], exist_ok=True)
        os.makedirs(dirs["mem_dir"], exist_ok=True)
    except Exception:
        ok = False
    return {
        "status": "ok" if ok else "degraded",
        "memory_backend": "file",
        **get_runtime_dirs(),
    }

# æŸ¥è¯¢è¿è¡ŒçŠ¶æ€ï¼ˆtraceï¼‰
@app.get("/state/{trace_id}")
def get_state(trace_id: str):
    try:
        return load_trace_state(trace_id)
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="trace_id not found")

@app.get("/states")
def list_states(session_id: Optional[str] = Query(None)):
    return {"items": list_trace_states(session_id=session_id)}

# å¯¼å…¥ä¸­æ–­ç®¡ç†å™¨
from deepagents.interrupt_manager import get_interrupt_manager
interrupt_manager = get_interrupt_manager()

@app.post("/interrupt/{trace_id}")
async def interrupt_task(trace_id: str):
    """ä¸­æ–­æŒ‡å®šä»»åŠ¡ - æ”¹è¿›ç‰ˆæœ¬"""
    try:
        # ç«‹å³æ‰“å°ä¸­æ–­æ—¥å¿—
        print(f"ğŸš« ç”¨æˆ·è¯·æ±‚ä¸­æ–­ä»»åŠ¡: {trace_id}")
        
        # ä½¿ç”¨ä¸­æ–­ç®¡ç†å™¨ä¸­æ–­ä»»åŠ¡
        success = interrupt_manager.interrupt_task(trace_id)
        
        if success:
            # è®°å½•ä¸­æ–­çŠ¶æ€åˆ°è¿è¡ŒçŠ¶æ€
            try:
                append_step(trace_id, "interrupt", "ok", {"interrupted_by": "user", "timestamp": time.time()})
                set_validation(trace_id, "interrupted", {"reason": "ç”¨æˆ·è¯·æ±‚ä¸­æ–­"})
            except Exception as e:
                print(f"âš ï¸ è®°å½•ä¸­æ–­çŠ¶æ€å¤±è´¥: {e}")
            
            print(f"âœ… ä»»åŠ¡ {trace_id} ä¸­æ–­æˆåŠŸ")
            
            return {
                "ok": True, 
                "trace_id": trace_id, 
                "message": "Task interrupted successfully",
                "timestamp": time.time()
            }
        else:
            print(f"âš ï¸ ä»»åŠ¡ {trace_id} ä¸å­˜åœ¨æˆ–å·²å®Œæˆ")
            return {
                "ok": False, 
                "trace_id": trace_id, 
                "message": "Task not found or already completed"
            }
            
    except Exception as e:
        print(f"âŒ ä¸­æ–­ä»»åŠ¡å¤±è´¥: {e}")
        return {
            "ok": False, 
            "trace_id": trace_id, 
            "error": str(e)
        }

@app.get("/interrupt/check/{trace_id}")
async def check_interrupted(trace_id: str):
    """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«ä¸­æ–­"""
    task_status = interrupt_manager.get_task_status(trace_id)
    return {
        "trace_id": trace_id,
        "interrupted": interrupt_manager.is_interrupted(trace_id),
        "task_status": task_status
    }

@app.get("/interrupt/status")
async def get_interrupt_status():
    """è·å–ä¸­æ–­çŠ¶æ€ä¿¡æ¯"""
    return interrupt_manager.get_all_status()

# æ–°å¢ï¼šæµå¼çŠ¶æ€æ›´æ–°ç«¯ç‚¹
from fastapi.responses import StreamingResponse
import asyncio

@app.get("/stream/state/{trace_id}")
async def stream_task_state(trace_id: str):
    """æµå¼æ¨é€ä»»åŠ¡çŠ¶æ€æ›´æ–°"""
    async def generate():
        last_state = None
        poll_count = 0
        max_polls = 6000  # 10åˆ†é’Ÿ
        
        while poll_count < max_polls:
            try:
                # è·å–å½“å‰çŠ¶æ€
                current_state = load_trace_state(trace_id)
                
                # æ£€æŸ¥çŠ¶æ€æ˜¯å¦æœ‰å˜åŒ–
                if current_state != last_state:
                    # å‘é€çŠ¶æ€æ›´æ–°
                    yield f"data: {json.dumps(current_state, ensure_ascii=False)}\n\n"
                    last_state = current_state
                    
                    # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                    is_completed = current_state.get("validation", {}).get("ok", False) or \
                        (current_state.get("todo") and all(item.get("status") == "completed" for item in current_state["todo"]))
                    
                    if is_completed:
                        yield f"data: {json.dumps({'status': 'completed'}, ensure_ascii=False)}\n\n"
                        break
                
                # æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
                if interrupt_manager.is_interrupted(trace_id):
                    yield f"data: {json.dumps({'status': 'interrupted'}, ensure_ascii=False)}\n\n"
                    break
                
                poll_count += 1
                await asyncio.sleep(0.1)  # 100msé—´éš”
                
            except FileNotFoundError:
                # ä»»åŠ¡çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¯èƒ½è¿˜åœ¨åˆå§‹åŒ–
                await asyncio.sleep(0.1)
                poll_count += 1
            except Exception as e:
                print(f"æµå¼çŠ¶æ€æ›´æ–°é”™è¯¯: {e}")
                yield f"data: {json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"
                break
        
        # å‘é€ç»“æŸä¿¡å·
        yield f"data: {json.dumps({'status': 'timeout'}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )

# æ–°å¢ï¼šå¿«é€ŸçŠ¶æ€æ£€æŸ¥ç«¯ç‚¹
@app.get("/quick/state/{trace_id}")
async def quick_check_state(trace_id: str):
    """å¿«é€Ÿæ£€æŸ¥ä»»åŠ¡çŠ¶æ€ï¼Œä¸è¿”å›å®Œæ•´æ•°æ®"""
    try:
        state = load_trace_state(trace_id)
        return {
            "trace_id": trace_id,
            "has_data": True,
            "validation_ok": state.get("validation", {}).get("ok", False),
            "steps_count": len(state.get("steps", [])),
            "todo_count": len(state.get("todo", [])),
            "is_interrupted": interrupt_manager.is_interrupted(trace_id)
        }
    except FileNotFoundError:
        return {
            "trace_id": trace_id,
            "has_data": False,
            "validation_ok": False,
            "steps_count": 0,
            "todo_count": 0,
            "is_interrupted": False
        }

if __name__ == "__main__":
    uvicorn.run(f"{__name__}:app", host="0.0.0.0", port=8002)
